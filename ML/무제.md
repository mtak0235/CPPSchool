# 머신러닝?

명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 분야

# 머신러닝 프로그램이 학습하는데 사용하는 데이터 집합?

training set

# training instance?

각각의 학습용 데이터

# 머신러닝을 왜 사용하는가?

전통적인 프로그램은 새로운 규칙이 생겼을 때 사용자가 매번 업데이트 해 줘야함.

머신러닝은 주기적으로 다시 훈련시키기만 하면 알아서 반영함.

# 머신러닝 학습 자동화?

MLOps

머신러닝 파이프라인

새롭게 얻은 데이터를 알고리즘을 다시 훈련하는데 사용하는 전 과정을 자동으로 진행

# 머신 러닝의 장점?

* 복잡한 문제 해결 가능
* 새로운 데이터에 쉽게 적응
* 복잡한 문제와 대량의 데이터에서 통찰을 얻음

# 머신러닝 적용 분류와 사례 4가지?

* 이미지 분류
  * 고품질 아몬드 분류
* 시맨틱 분할
  * 뇌 종양 진단
* 텍스트 분류
  * 댓글 욕설 감지
* 텍스트 요약
  * 긴 문서 자동 요약
* 자연어 이해
  * 챗봇
* 회귀 분석
  * 내년 수익 예측
* 음성 인식
  * 음성 명령에 반응하는 앱
* 군집 작업
  * 구매 이력 기반 고객 분류
* 이상치 탐지
  * 신용카드 부정 거래 감지
* 데이터 시각화
  * 그래프 효율적으로 표현
* 추천 시스템
  * 구매 이력 기반 상품 추천
* 강화 학습
  * 지능형 게임 봇

# 머신러닝 분류 기준 3가지?

1. 훈련 지도 여부
2. 실시간 훈련 여부
3. 예측 모델 사용 여부

# 분류 기준은 상호 배타적이다 .

ㅗ.

# 머신 러닝을 훈련 지도 여부로 분류하라

* 지도 학습
* 비지도 학습
* 준지도 학습
* 강화 학습

# 머신 러닝을 실시간 훈련 여부로 분류하라

* 온라인 학습
* 배치 학습

# 머신 러닝을 예측 모델 사용 여부로 분류하라

* 사례 기반 학습
* 모델 기반 학습

# 정답이 있는 학습은 비지도 학습이다.

ㅗ. 지도 학습이다.

# 대표적인 지도 학습 2가지

1. 분류
2. 회귀

# 지도 학습 알고리즘을 3가지만

1. linear regression
2. logistic regression
3. support vector machine
4. knn
5. decision tree & random forest
6. neural network

# 대표적인 비지도학습 4가지

1. 군집
2. 시각화
3. 차원 축소
4. 연관규칙 학습

# 차원 축소의 장점?

상관관계가 있는 여러 특성을 하나로 합쳐서,
메모리 사용 공간이 줄어들고 + 훈련 실행 속도가 빨라져,
머신러닝 알고리즘 성능이 향상

# 준지도 학습에서 훈련데이터에 label이 없다. 

ㅗ. 일부만 있다. 

# 준지도 학습은 지도 학습  후 비지도 학습을 한다. 

ㅗ. 비지도 학습을 통해 군집을 분류한 후, 지도 학습을 시킨다. 

# 강화 학습이란?

환경을 정의하고 
알고리즘이 환겨 안에서 행동을 관찰하고 보상 || 벌점을 제공하고
agent는 보상이 최대화 되도록 행동을 결정한다. 

# 컴퓨팅 자원이 한정적이거나, 새로운 데이터가 자주 들어오면 배치 학습해야한다.  

ㅗ. 온라인 학습 해야한다. 

# 매우 큰 데이터셋을 활용한다면 배치학습니다. 

ㅗ. 온라인 학습해야 한다. 

# 예측을 위해 기존 샘플과의 유사도를 측정하는 머신러닝 방식은?

사례 기반 학습

# 모델 기반 학습에서는 사례 기반 학습과 달리 모델을 미리 정하고 모델을 훈련시킨다.

맞음.

# 비용 함수 값이 클수록 모델은 좋다.

ㅗ. 값이 작을수록 좋다.

# 규제를 완화하면 과대 적합을 줄일 수 있다. 

 ㅗ. 과대 적합 막으려고 규제 하는건데? 규제하면 단순해져.

# 규제를 강화하면 과소 적합을 막을 수 있다. 

ㅗ. 규제를 완화해야 generalized 되지. 

# 과대 적합 해결 방법

1. 훈련 데이터에 있는 특성 수 줄인다.
2. 모델에 제약을 가해 단순화 시킨다.
3. 훈련 데이터 늘인다.
4. 훈련 데이터의 오류 데이터를 수정하거나 이상치를 제거한다.
5. 모델의 차수를 줄이거나 파라미터 수를 줄인다. 

# 하이퍼 파라미터가 많아질수록, 규제가 많아진다.

ㅇㅇ

# 하이퍼 파라미터는 학습 알고리즘의 동작 방식을 결정한다.

ㅇㅇ

# 훈련오차에 비해 일반화 오차가 적으면 과소적합이다.

ㅗ. 과대 적합이겠자.

# 검증 테스트가 필요한 이유는?

테스트 데이터셋에 과적합 되는 것을 막기 위해서다. 겸사겸사 모델의 하이퍼 파라미터도 조정한다.

# 검증 테스트에 과적합 되는건 어떻게 막을건가?

교차 검증읋 하면 된다. 

- 전체 데이터셋을 k개의 폴드로 나눕니다.
- 각 폴드를 한 번씩 검증 세트로 사용하고, 나머지 폴드는 훈련 세트로 사용합니다.
- 이 과정을 k번 반복하여 모든 폴드가 한 번씩 검증 세트로 사용되도록 합니다.
- 각 반복에서 모델을 훈련하고 검증 세트에 대한 성능을 평가합니다.
- k번의 성능을 평균내어 최종 성능을 산출합니다.

# 데이터 불일치는 언제 발생하나?

훈련 데이터가 실전에 사용되는 데이터를 대변하지 못할 때.

# No Free Lunch

주어진 데이터셋에 가장 적합한 모델은 미리 알 수 없음.

----

# 다음 중 오차에 더 민감한 것은?

![image-20240415191907050](/Users/mtak/Library/Application Support/typora-user-images/image-20240415191907050.png)

![image-20240415191920731](/Users/mtak/Library/Application Support/typora-user-images/image-20240415191920731.png)

RMSE

# 샘플링을 하는 두가지 방법

1. 무작위 sampling
2. 계층적 sampling

# housing 데이터 셋에 대해 ocean_proximity를 기준으로 계층적 sampling을 하려 한다. 

필요한 훈련셋:테스트셋=8:2이다. 계층적으로 sampling 된 것을 보여라.

```python
from sklearn.model_selection import StratifiedShuffleSplit
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=777)
for train_index, test_index in split.split(housing, housing["ocean_proximity"]):
  train_datasets = housing.loc[train_index]
  test_datasets = housing.loc[test_index]
print(train_datasets['ocean_proximity'].value_counts() / len(train_datasets))
print(test_datasets['ocean_proximity'].value_counts()/ len(test_datasets))
```

# housing의 median_house_value가 다른 특성과 어떤 상관관계가 있는지 descending으로 알려줘

```python
housing_corr = housing.loc[:, housing.columns != 'ocean_proximity'].corr() 
housing_corr['median_hous_value'].sort_vlaues(ascending=False)
```

# 결과물이 다음과 같을 때, 두번째로 상관관계가 높은 것은?

![image-20240415210513353](/Users/mtak/Library/Application Support/typora-user-images/image-20240415210513353.png)

latitude. 0에서 멀수록 상관 관계가 높다. 

# 모델 학습을 효율적으로 하기 진행하기 위해 주어진 데이터를 변환시키는 것을 뭐라고 하는가?

데이터 전처리

# 수치형 데이터 전처리 과정 3가지

1. 데이터 정제
2. 조합 특성 추가
3. 특성 스캐일링

# 특성 스케일링이란?

특성간 범주 크기를 맞추는 작업

# 범주형 데이터 전처리 과정 1가지

원 핫 인코딩

# (추정기)estimator란?

데이터 셋을 기반으로,  모델 파라미터들을 추정하는 객체. 

> 데이터 학습

# 다음 estimator 예제에서 빈 칸에 들어갈 메소드명은?

```python
from sklearn.linear_model import LinearRegression

# 데이터 준비
X = [[1], [2], [3]]
y = [2, 4, 6]

# 추정기 객체 생성
model = LinearRegression()

# 모델 학습
model.[   ](X, y)

# 모델 파라미터 확인
print("Coefficient:", model.coef_)
print("Intercept:", model.intercept_)
```

`fit`

# transformer란?

1. `transformer.fit(data)`로 평균, 표준편차, 고윳값 등 데이터를 변환하는데 필요한 정보들 계산
2. `final_ data = transformer.transform(data)`로 데이터 변환

> 데이터 변환

# predictor란?

만들어진  모델로  테스트 셋에 대한 결과 예측

# 다음 코드를 설명하라

```python
from sklearn.preprocessing import OneHotEncoder
cat_encoder = OneHotEncoder()
housing_cat_1hot = cat_encoder.fit_transform(housing[['ocean_proximity']])
print(housing_cat_1hot.toarray())
```

OneHotEncoder 클래스: 범주형 변수를 One-Hot 인코딩으로 변환합니다.

fit_transform = 범주형 데이터들의 고윳값을 찾아냄 + 데이터 인코딩

# 다음 코드에서 빈 곳에 들어갈 메소드는?

```python
from sklearn.linear_model import LinearRegression

# 데이터 준비
X_train = [[1], [2], [3]]
y_train = [2, 4, 6]
X_test = [[4], [5]]

# 예측기 객체 생성
model = LinearRegression()

# 모델 학습
model.fit(X_train, y_train)

# 예측 수행
y_pred = model.[    ](X_test)

print("Predictions:", y_pred)

# 예측 성능 평가 (R^2 score)
score = model.[   ](X_test, [8, 10])
print("R^2 Score:", score)
```

* `predict`
* `score`

# housing에서 “total_bedrooms” col이 NaN인 row를 날리는 코드를 작성하라

`housing.dropna(subset=["total_bedrooms"], inplace=True)`

# housing에서 “total_bedrooms”coldl NaN이면 중간 값으로 채워넣는 코드를 작성해라.

```python
m = housing["total_bedrooms"].median()
housing["total_bedrooms"].fillna(m, inplace=True)
```

# min-max scaling이란?

x = (x - min) / (max - min)

# min-max에서 이상치가 매우 크면 무슨 일이 벌어지나?

분모가 커져서 변환된 값이 0에 몰린다.

# 표준화는 정규화이다.

ㅗ. min-max scaling이 정규화(normalization)이고, 표준화(standardization)은 x = (x - avg) / 표준편차**2 

# 정규화가 표준화보다 이상치 영향을 더 많이 받는다. 

ㅇㅇ

# transformer.fit()도  transformer.transform()처럼 훈련 데이터에 대해서만 적용한다. 

fit()는 훈련 데이터에만 사용하는 것이 맞는데, transform()은 훈련데이터 뿐 아니라 테스트 데이터에도 사용된다.

# class sklearn.pipeline.Pipeline(steps) 란?

데이터 전처리 transformers와 모델 훈련 estimator를 연결해 놓은 것.

# 회귀 모델의 성능 측정 지표

* rmse
* mae

# RMSE = ?

![image-20240416222518089](/Users/mtak/Library/Application Support/typora-user-images/image-20240416222518089.png)

# MAE = ?

![image-20240416223928886](/Users/mtak/Library/Application Support/typora-user-images/image-20240416223928886.png)



# k겹 교차 검증에 대해 설명하라

1. 훈련 세트를 fold라 불리는 k개의 부분집합으로 무작위로 분할
2. 총 k번 지정된 모델을 훈련
   1. 훈련 할 때 마다 매번 다른 하나의 폴드를 평가에 사용
   2. 나머지 k  - 1 개의 폴드를 이용해 훈련
3. 최종적으로 k번의 평가 결과가 담긴 배열 생성

# 다음 코드 중 틀린 내용은?

```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring="mean_squared_error", cv=10)
tree_rmse_scores = np.sqrt(scores)
```

* line2: mean_squared_error -> neg_mean_squared_error
* line3: scores -> -scores

# 앙상블 학습이란?

여러 다른 모델을 모아서 하나의 모델을 만드는 기법

# 모델 세뷰 튜닝 3가지

1. 그리드 탐색
2. 랜덤 탐색
3. 앙상블 방법

# 다음 코드에서 총 훈련 횟수는?

```python
from sklearn.model_selection import GridSearchCV
param_grid = [
  {'n_estimators': [1,2,3], 'max_features':[1,2,3,4]}
  {'boot_strap': [False], 'n_estimators':[1,2], 'max_features':[1,2,3]}
]
forest_reg = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)
```

(3 * 4 + 2 * 3) * 5 = 90

# 다음 코드에서 총 훈련 횟수는?

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

param_distribs = {
    'n_estimators': randint(low=1, high=200),
    'max_features': randint(low=1, high=8),
}

forest_reg = RandomForestRegressor(random_state=42)
rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,
                                n_iter=10, cv=5, scoring='neg_mean_squared_error',
                                random_state=42)
rnd_search.fit(housing_prepared, housing_label)
```

10 * 5 = 50

----

# 다음 관계식은 multivariable인가 multivariate인가?

![image-20240417143329149](/Users/mtak/Library/Application Support/typora-user-images/image-20240417143329149.png)

multivariate

# 다음 관계식은 multivariable인가 multivariate인가?

![image-20240417143346575](/Users/mtak/Library/Application Support/typora-user-images/image-20240417143346575.png)

multivariable

# 